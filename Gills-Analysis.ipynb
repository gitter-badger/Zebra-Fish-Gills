{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the gills\n",
    "- Oleksiy and Flu scanned them\n",
    "- Dea delineated them\n",
    "- David does the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "seaborn.set_style('dark')\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import os\n",
    "import platform\n",
    "import pandas\n",
    "import glob\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import scipy.stats\n",
    "import numpy\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style plots\n",
    "seaborn.set_style(\"whitegrid\")\n",
    "seaborn.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and output defaults\n",
    "plt.rc('image', cmap='gray', interpolation='nearest')  # Display all images in b&w and with 'nearest' interpolation\n",
    "# plt.rcParams['figure.figsize'] = (16, 9)  # Size up figures a bit\n",
    "plt.rcParams['savefig.dpi'] = 300  # Save (PNG) images with a higher DPI, since Authorea cannot import PDFs...\n",
    "plt.rcParams[\"savefig.transparent\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scale bar\n",
    "plt.rcParams['scalebar.location'] = 'lower right'\n",
    "plt.rcParams['scalebar.frameon'] = False\n",
    "plt.rcParams['scalebar.color'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_hash():\n",
    "    \"\"\"\n",
    "    Get the current git hash from the repository.\n",
    "    Based on http://stackoverflow.com/a/949391/323100 and\n",
    "    http://stackoverflow.com/a/18283905/323100\n",
    "    \"\"\"\n",
    "    from subprocess import Popen, PIPE\n",
    "    import os\n",
    "    gitprocess = Popen(['git', '--git-dir', os.path.join(os.getcwd(), '.git'),\n",
    "                        'rev-parse', '--short', '--verify', 'HEAD'],\n",
    "                       stdout=PIPE)\n",
    "    (output, _) = gitprocess.communicate()\n",
    "    return output.strip().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixelsize(logfile):\n",
    "    \"\"\"Get the pixel size from the scan log file\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Image Pixel' in line and 'Scaled' not in line:\n",
    "                pixelsize = float(line.split('=')[1])\n",
    "    return(pixelsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(value1, value2):\n",
    "    \"\"\"\n",
    "    We use this over and over in the results part.\n",
    "    Just a helper function to print out the percentage increase.\n",
    "    \"\"\"\n",
    "    p = value2 / value1\n",
    "    p -= 1\n",
    "    p *= 100\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(p):\n",
    "    \"\"\"See the bottom of https://git.io/vQbWV\"\"\"\n",
    "    if p < 0.0001:\n",
    "        return \"**** (p=%.3f)\" % p\n",
    "    elif (p < 0.001):\n",
    "        return \"*** (p=%.3f)\" % p\n",
    "    elif (p < 0.01):\n",
    "        return \"** (p=%.3f)\" % p\n",
    "    elif (p < 0.05):\n",
    "        return \"* (p=%.3f)\" % p\n",
    "    else:\n",
    "        return \"not significant (p=%.3f)\" % p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on the fast SSD from here on!\n",
    "FastSSD = True\n",
    "if 'debian' in platform.dist():\n",
    "    if FastSSD:\n",
    "        StartDir = '/media/habi/Fast_SSD/'\n",
    "    else:\n",
    "        StartDir = '/media/habi/Blue Seagate/'\n",
    "else:\n",
    "    if FastSSD:\n",
    "        StartDir = 'F:/'\n",
    "    else:\n",
    "        StartDir = 'G:/'\n",
    "RootFolder = os.path.join(StartDir, 'Zebra-Fish_Matthias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are loading all the data from /media/habi/Fast_SSD/Zebra-Fish_Matthias\n"
     ]
    }
   ],
   "source": [
    "print('We are loading all the data from %s' % RootFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are saving the output images to /home/habi/P/Documents/Zebrafish-Gills/Output/de99922\n"
     ]
    }
   ],
   "source": [
    "# Make directory for output\n",
    "OutPutDir = os.path.join(os.getcwd(), 'Output', get_git_hash())\n",
    "print('We are saving the output images to %s' % OutPutDir)\n",
    "os.makedirs(OutPutDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all plots identically\n",
    "lines = 5\n",
    "# And then do something like\n",
    "# plt.subplot(lines, numpy.ceil(len(ROIFolder) / float(lines)), c + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get going, now that we set up everything..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from the microCT scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the samples we scanned\n",
    "try:\n",
    "    SampleNames = sorted(next(os.walk(RootFolder))[1])\n",
    "except StopIteration:\n",
    "    print('Please mount the fast SSD!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Folder we don't want\n",
    "if not FastSSD:\n",
    "    SampleNames.remove('Original SEM Bilder')\n",
    "    SampleNames.remove('tresholding_estimation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the information into a pandas dataframe\n",
    "Data = pandas.DataFrame({'Sample': SampleNames})\n",
    "Data['Folder'] = [os.path.join(RootFolder, s) for s in SampleNames]\n",
    "Data['LogFile'] = [sorted(glob.glob(os.path.join(f, 'proj', '*.log')))[0] for f in Data.Folder]\n",
    "Data['RecFolder'] = [os.path.join(RootFolder, f, 'rec') for f in Data.Folder]\n",
    "Data['VOIFolder'] = [os.path.join(RootFolder, f, 'VOI') for f in Data.Folder]\n",
    "Data['OverviewName'] = [glob.glob(os.path.join(r, '*spr.bmp'))[0] for r in Data.RecFolder]\n",
    "Data['ReconstructionNames'] = [sorted(glob.glob(os.path.join(r, '*.png'))) for r in Data.RecFolder]\n",
    "# Try to be a bit clever with loading the VOI slices\n",
    "# They are saved as either PNG or BMP, and there's also some other stuff in the folder...\n",
    "Data['VOINames'] = [sorted(glob.glob(os.path.join(r, '*rec*[0123456789].*'))) for r in Data.VOIFolder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an 'experiment' column, which we use for the box plots below\n",
    "def whichexperiment(i):\n",
    "    '''Categorize  into 'Swimmer' or 'Control' '''\n",
    "    if 'immer' in i:\n",
    "        return 'Swimmer'\n",
    "    if 'ontrol' in i:\n",
    "        return 'Control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Experiment'] = [whichexperiment(name) for name in Data.Folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color plot based on label (mrt, ctrl or bb)\n",
    "def color_based_on_experiment(i):\n",
    "    '''Colorize into 'Swimmer' or 'Control' '''\n",
    "    if 'ontrol' in i:\n",
    "        return seaborn.color_palette()[0]\n",
    "    if 'immer' in i:\n",
    "        return seaborn.color_palette()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Color'] = [color_based_on_experiment(name) for name in Data.Folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Pixel sizes of the scans\n",
    "# in micrometers\n",
    "Data['PixelSize'] = [get_pixelsize(logfile) for logfile in Data.LogFile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the voxel volume, which we'll use later on\n",
    "# Let's use microlitre as unit\n",
    "Data['VoxelVolume'] = [ps ** 3 * 1e-9 for ps in Data.PixelSize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the other data (XLS files from Matthias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fish length data\n",
    "morphologyfile = glob.glob(os.path.join('XLS*', '*morph*.xlsx'))[0]\n",
    "# Load all the morphology data into its own dataframe\n",
    "# With a hat tip to https://stackoverflow.com/a/49442625/323100\n",
    "Morphology = pandas.read_excel(morphologyfile,\n",
    "                               usecols='E:H,K:N',\n",
    "                               skiprows=3,\n",
    "                               nrows=27,\n",
    "                               names=['Length Swimmer Before',\n",
    "                                      'Weight Swimmer Before',\n",
    "                                      'Length Control Before',\n",
    "                                      'Weight Control Before',\n",
    "                                      'Length Swimmer After',\n",
    "                                      'Weight Swimmer After',\n",
    "                                      'Length Control After',\n",
    "                                      'Weight Control After'])\n",
    "# Drop unneeded rows\n",
    "Morphology.drop([10, 11, 12, 13, 14, 15, 16], inplace=True)\n",
    "# Get ourselves the fish number in a column\n",
    "Morphology['Fish'] = range(1, 21)\n",
    "Morphology['Fish'][10:] = range(1, 11)\n",
    "# Get ourselves the gender in a column\n",
    "Morphology['Gender'] = 'Female'\n",
    "Morphology['Gender'][10:] = 'Male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Massage the morphology data into a new dataframe for displaying it nicely\n",
    "# One fish for the swimmers after training died, so we temporarily\n",
    "# replace it's data with 9999 to we can still do the 'dropna' dance below\n",
    "Morphology.fillna(value=9999, inplace=True)\n",
    "# First, pull together so we get a proper 'Training' column\n",
    "mo = pandas.concat([Morphology[['Gender',\n",
    "                                'Fish',\n",
    "                                'Length Swimmer After',\n",
    "                                'Length Control After',\n",
    "                                'Weight Swimmer After',\n",
    "                                'Weight Control After']],\n",
    "                    Morphology[['Gender',\n",
    "                                'Fish',\n",
    "                                'Length Swimmer Before',\n",
    "                                'Length Control Before',\n",
    "                                'Weight Swimmer Before',\n",
    "                                'Weight Control Before']]])\n",
    "mo['Length Swimmer'] = pandas.concat([mo['Length Swimmer After'].dropna(),\n",
    "                                      mo['Length Swimmer Before'].dropna()])\n",
    "mo['Length Control'] = pandas.concat([mo['Length Control After'].dropna(),\n",
    "                                      mo['Length Control Before'].dropna()])\n",
    "mo['Weight Swimmer'] = pandas.concat([mo['Weight Swimmer After'].dropna(),\n",
    "                                      mo['Weight Swimmer Before'].dropna()])\n",
    "mo['Weight Control'] = pandas.concat([mo['Weight Control After'].dropna(),\n",
    "                                      mo['Weight Control Before'].dropna()])\n",
    "mo['Training'] = ['Before' if o > 0 else 'After' for o in mo['Length Control Before']]\n",
    "# Then, pull together so we get a proper 'Experiment' column\n",
    "mo2 = pandas.concat([mo[['Gender',\n",
    "                         'Fish',\n",
    "                         'Training',\n",
    "                         'Length Swimmer',\n",
    "                         'Weight Swimmer']],\n",
    "                     mo[['Gender',\n",
    "                         'Fish',\n",
    "                         'Training',\n",
    "                         'Length Control',\n",
    "                         'Weight Control']]])\n",
    "mo2['Length'] = pandas.concat([mo2['Length Swimmer'].dropna(),\n",
    "                               mo2['Length Control'].dropna()])\n",
    "mo2['Weight'] = pandas.concat([mo2['Weight Swimmer'].dropna(),\n",
    "                               mo2['Weight Control'].dropna()])\n",
    "mo2['Experiment'] = ['Swimmer' if i > 0 else 'Control' for i in mo2['Length Swimmer']]\n",
    "# Set that one fish back to NaN\n",
    "mo2.replace(9999, numpy.nan, inplace=True)\n",
    "# Set the massaged data back to the Morphology dataframe\n",
    "Morphology = mo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the respirometry data\n",
    "# Since it's in a 'messy' xls sheet, we cannot do it in one go, but do it in four cells :)\n",
    "respirometryfile = glob.glob(os.path.join('XLS*', '*', 'Respirometry*.xlsx'))[0]\n",
    "# Based on https://stackoverflow.com/a/49442625/323100\n",
    "# Load O2 at start\n",
    "o2 = pandas.read_excel(respirometryfile, index_col=None, skiprows=1, usecols='H')\n",
    "Data['O2 consumption start'] = pandas.concat([o2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load O2 at start, normalized\n",
    "o2_norm = pandas.read_excel(respirometryfile, index_col=None, skiprows=1, usecols='I')\n",
    "# Unfortunately, Matthias saved some more stuff into this colum, so we just drop some cells\n",
    "o2_norm.drop([10, 21, 22], inplace=True)\n",
    "Data['O2 consumption start normalized'] = pandas.concat([o2_norm], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load O2 at the end\n",
    "o2_end = pandas.read_excel(respirometryfile, index_col=None, skiprows=1, usecols='P')\n",
    "Data['O2 consumption end'] = pandas.concat([o2_end], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load O2 at end, normalized\n",
    "o2_norm_end = pandas.read_excel(respirometryfile, index_col=None, skiprows=1, usecols='Q')\n",
    "# Unfortunately, Matthias saved some more stuff into this colum, so we just drop some cells\n",
    "o2_norm_end.drop([10, 20], inplace=True)\n",
    "Data['O2 consumption end normalized'] = pandas.concat([o2_norm_end], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check the data\n",
    "# Data[['Sample',\n",
    "#       'O2 consumption start', 'O2 consumption start normalized',\n",
    "#       'O2 consumption end', 'O2 consumption end normalized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Massage the respirometry data into a new dataframe for displaying it nicely\n",
    "# On some respirometry data we have NaN.\n",
    "# Let's fill this with 9999, so that we can merge the before/after data\n",
    "Data.fillna(value=9999, inplace=True)\n",
    "# Generate us a new dataframe\n",
    "respirometry = pandas.concat([Data[['Sample', 'Experiment', 'O2 consumption start normalized']],\n",
    "                              Data[['Sample', 'Experiment', 'O2 consumption end normalized']]])\n",
    "# Let's put NaN back\n",
    "Data.replace(9999, numpy.nan, inplace=True)\n",
    "# Merge, based on https://stackoverflow.com/a/10972557/323100\n",
    "respirometry['o2'] = pandas.concat([respirometry['O2 consumption start normalized'].dropna(),\n",
    "                                    respirometry['O2 consumption end normalized'].dropna()]).reindex_like(respirometry)\n",
    "# Make us an experiment state, so we can 'hue' on this later\n",
    "respirometry['Training'] = ['Before' if o > 0 else 'After' for o in respirometry['O2 consumption start normalized']]\n",
    "# Set that one value back to NaN\n",
    "respirometry.replace(9999, numpy.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>O2 consumption end normalized</th>\n",
       "      <th>O2 consumption start normalized</th>\n",
       "      <th>Sample</th>\n",
       "      <th>o2</th>\n",
       "      <th>Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057310</td>\n",
       "      <td>Control01</td>\n",
       "      <td>0.057310</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>Control02</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>Control03</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>Control04</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024857</td>\n",
       "      <td>Control05</td>\n",
       "      <td>0.024857</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>Control06</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>Control07</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044571</td>\n",
       "      <td>Control08</td>\n",
       "      <td>0.044571</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>Control09</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>Control10</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028071</td>\n",
       "      <td>Swimmer01</td>\n",
       "      <td>0.028071</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037448</td>\n",
       "      <td>Swimmer02</td>\n",
       "      <td>0.037448</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023172</td>\n",
       "      <td>Swimmer03</td>\n",
       "      <td>0.023172</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027931</td>\n",
       "      <td>Swimmer04</td>\n",
       "      <td>0.027931</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024857</td>\n",
       "      <td>Swimmer05_Rescan</td>\n",
       "      <td>0.024857</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>Swimmer06</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>Swimmer07</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052071</td>\n",
       "      <td>Swimmer08</td>\n",
       "      <td>0.052071</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029538</td>\n",
       "      <td>Swimmer09</td>\n",
       "      <td>0.029538</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>Swimmer10</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>Before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control01</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control02</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control03</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control04</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.021462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control05</td>\n",
       "      <td>0.021462</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control06</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.020571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control07</td>\n",
       "      <td>0.020571</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.034552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control08</td>\n",
       "      <td>0.034552</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.031655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control09</td>\n",
       "      <td>0.031655</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.040632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Control10</td>\n",
       "      <td>0.040632</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>0.038951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer01</td>\n",
       "      <td>0.038951</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer02</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>0.031619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer03</td>\n",
       "      <td>0.031619</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer04</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer05_Rescan</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer06</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>0.044357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer07</td>\n",
       "      <td>0.044357</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer08</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>0.035379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer09</td>\n",
       "      <td>0.035379</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Swimmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swimmer10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment  O2 consumption end normalized  O2 consumption start normalized  \\\n",
       "0     Control                            NaN                         0.057310   \n",
       "1     Control                            NaN                         0.020400   \n",
       "2     Control                            NaN                         0.035143   \n",
       "3     Control                            NaN                         0.021333   \n",
       "4     Control                            NaN                         0.024857   \n",
       "5     Control                            NaN                         0.028615   \n",
       "6     Control                            NaN                         0.052600   \n",
       "7     Control                            NaN                         0.044571   \n",
       "8     Control                            NaN                         0.025714   \n",
       "9     Control                            NaN                         0.034222   \n",
       "10    Swimmer                            NaN                         0.028071   \n",
       "11    Swimmer                            NaN                         0.037448   \n",
       "12    Swimmer                            NaN                         0.023172   \n",
       "13    Swimmer                            NaN                         0.027931   \n",
       "14    Swimmer                            NaN                         0.024857   \n",
       "15    Swimmer                            NaN                         0.055500   \n",
       "16    Swimmer                            NaN                         0.030000   \n",
       "17    Swimmer                            NaN                         0.052071   \n",
       "18    Swimmer                            NaN                         0.029538   \n",
       "19    Swimmer                            NaN                         0.025556   \n",
       "0     Control                       0.028200                              NaN   \n",
       "1     Control                       0.021153                              NaN   \n",
       "2     Control                       0.017172                              NaN   \n",
       "3     Control                       0.029172                              NaN   \n",
       "4     Control                       0.021462                              NaN   \n",
       "5     Control                       0.018429                              NaN   \n",
       "6     Control                       0.020571                              NaN   \n",
       "7     Control                       0.034552                              NaN   \n",
       "8     Control                       0.031655                              NaN   \n",
       "9     Control                       0.040632                              NaN   \n",
       "10    Swimmer                       0.038951                              NaN   \n",
       "11    Swimmer                       0.030000                              NaN   \n",
       "12    Swimmer                       0.031619                              NaN   \n",
       "13    Swimmer                       0.029586                              NaN   \n",
       "14    Swimmer                       0.033556                              NaN   \n",
       "15    Swimmer                       0.033800                              NaN   \n",
       "16    Swimmer                       0.044357                              NaN   \n",
       "17    Swimmer                       0.031400                              NaN   \n",
       "18    Swimmer                       0.035379                              NaN   \n",
       "19    Swimmer                            NaN                              NaN   \n",
       "\n",
       "              Sample        o2 Training  \n",
       "0          Control01  0.057310   Before  \n",
       "1          Control02  0.020400   Before  \n",
       "2          Control03  0.035143   Before  \n",
       "3          Control04  0.021333   Before  \n",
       "4          Control05  0.024857   Before  \n",
       "5          Control06  0.028615   Before  \n",
       "6          Control07  0.052600   Before  \n",
       "7          Control08  0.044571   Before  \n",
       "8          Control09  0.025714   Before  \n",
       "9          Control10  0.034222   Before  \n",
       "10         Swimmer01  0.028071   Before  \n",
       "11         Swimmer02  0.037448   Before  \n",
       "12         Swimmer03  0.023172   Before  \n",
       "13         Swimmer04  0.027931   Before  \n",
       "14  Swimmer05_Rescan  0.024857   Before  \n",
       "15         Swimmer06  0.055500   Before  \n",
       "16         Swimmer07  0.030000   Before  \n",
       "17         Swimmer08  0.052071   Before  \n",
       "18         Swimmer09  0.029538   Before  \n",
       "19         Swimmer10  0.025556   Before  \n",
       "0          Control01  0.028200    After  \n",
       "1          Control02  0.021153    After  \n",
       "2          Control03  0.017172    After  \n",
       "3          Control04  0.029172    After  \n",
       "4          Control05  0.021462    After  \n",
       "5          Control06  0.018429    After  \n",
       "6          Control07  0.020571    After  \n",
       "7          Control08  0.034552    After  \n",
       "8          Control09  0.031655    After  \n",
       "9          Control10  0.040632    After  \n",
       "10         Swimmer01  0.038951    After  \n",
       "11         Swimmer02  0.030000    After  \n",
       "12         Swimmer03  0.031619    After  \n",
       "13         Swimmer04  0.029586    After  \n",
       "14  Swimmer05_Rescan  0.033556    After  \n",
       "15         Swimmer06  0.033800    After  \n",
       "16         Swimmer07  0.044357    After  \n",
       "17         Swimmer08  0.031400    After  \n",
       "18         Swimmer09  0.035379    After  \n",
       "19         Swimmer10       NaN    After  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respirometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SEM data\n",
    "semfile = glob.glob(os.path.join('XLS*', '*', '*electron*.xlsx'))[0]\n",
    "# Load filament count\n",
    "# We could probably do it in one go as above, but then 'squeeze' doesn't seem to discard the empty lines...\n",
    "Filaments = pandas.DataFrame()\n",
    "Filaments['Swimmer Count'] = pandas.read_excel(semfile, usecols='G', nrows=199, squeeze=True)\n",
    "Filaments['Control Count'] = pandas.read_excel(semfile, usecols='AA', nrows=199, squeeze=True, na_values='Keine Daten')\n",
    "# Load filament length\n",
    "Filaments['Swimmer Length'] = pandas.read_excel(semfile, usecols='Q', nrows=199, squeeze=True)\n",
    "Filaments['Control Length'] = pandas.read_excel(semfile, usecols='AK', nrows=199, squeeze=True, na_values='Keine Daten')\n",
    "# Scale from Fiji measurement units to um\n",
    "Filaments['Swimmer Length'] *= 1 / 0.6 * 100\n",
    "Filaments['Control Length'] *= 1 / 0.6 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the speed assessment data\n",
    "speedfile = glob.glob(os.path.join('XLS*', '*speed*.xlsx'))[0]\n",
    "Speed = pandas.read_excel(speedfile,\n",
    "                          usecols='B,E,O,R,U',\n",
    "                          skiprows=3,\n",
    "                          nrows=29,\n",
    "                          names=['Swimmer Before',\n",
    "                                 'Control Before',\n",
    "                                 'Swimmer 3wk',\n",
    "                                 'Swimmer After',\n",
    "                                 'Control After'])\n",
    "# Drop unneeded colums and reset the numbering (index)\n",
    "Speed.drop([10, 11, 12, 13, 14, 15, 16, 17, 18], inplace=True)\n",
    "Speed.reset_index(inplace=True, drop=True)\n",
    "# Convert the weird Excel time to something we can actually use...\n",
    "# Pandas parses the M:S Matthias entered as H:M:00\n",
    "# It would probably easy to do this via a parser, but just converting it with a Timedelta is quicker\n",
    "# (Which just means I gave up after putting keywords into a search engine for two hours\n",
    "Speed['Swimmer Before'] = [pandas.Timedelta(minutes=time.hour,\n",
    "                                            seconds=time.minute) for time in Speed['Swimmer Before']]\n",
    "Speed['Control Before'] = [pandas.Timedelta(minutes=time.hour,\n",
    "                                            seconds=time.minute) for time in Speed['Control Before']]\n",
    "# Since we have NaN (as float) in the column (data for fish 10 is missing)\n",
    "# we jump through this super-complicated hoop to covert the time to timedelta\n",
    "# with a tip to the hat to https://stackoverflow.com/a/25142407/323100\n",
    "Speed['Swimmer 3wk'] = [pandas.Timedelta(minutes=time.hour, seconds=time.minute)\n",
    "                        if not pandas.isnull(time) else pandas.to_datetime('13000101',\n",
    "                                                                           format='%Y%m%d',\n",
    "                                                                           errors='coerce')\n",
    "                        for time in Speed['Swimmer 3wk']]\n",
    "Speed['Swimmer After'] = [pandas.Timedelta(minutes=time.hour, seconds=time.minute)\n",
    "                          if not pandas.isnull(time) else pandas.to_datetime('13000101',\n",
    "                                                                             format='%Y%m%d',\n",
    "                                                                             errors='coerce')\n",
    "                          for time in Speed['Swimmer After']]\n",
    "Speed['Control After'] = [pandas.Timedelta(minutes=time.hour,\n",
    "                                           seconds=time.minute) for time in Speed['Control After']]\n",
    "# Get ourselves the fish number in a column\n",
    "Speed['Fish'] = range(1, 21)\n",
    "Speed['Fish'][10:] = range(1, 11)\n",
    "# Get ourselves the gender in a column\n",
    "Speed['Gender'] = 'Female'\n",
    "Speed['Gender'][10:] = 'Male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Massage the speed data into a new dataframe for displaying it nicely\n",
    "# One fish for the swimmers after training died missing,\n",
    "# replace it's data with 9999 so we can still do the 'dropna' dance below\n",
    "Speed.fillna(value=9999, inplace=True)\n",
    "# First, pull together so we get a proper 'Training' column\n",
    "sp = pandas.concat([Speed[['Gender',\n",
    "                           'Fish',\n",
    "                           'Swimmer After',\n",
    "                           'Control After']],\n",
    "                    Speed[['Gender',\n",
    "                           'Fish',\n",
    "                           'Swimmer Before',\n",
    "                           'Control Before']]])\n",
    "sp['Swimmer'] = pandas.concat([sp['Swimmer After'].dropna(),\n",
    "                            sp['Swimmer Before'].dropna()])\n",
    "sp['Control'] = pandas.concat([sp['Control After'].dropna(),\n",
    "                               sp['Control Before'].dropna()])\n",
    "sp['Training'] = ['Before' if o > pandas.Timedelta(seconds=1) else 'After' for o in sp['Control Before']]\n",
    "# Then, pull together so we get a proper 'Experiment' column\n",
    "sp2 = pandas.concat([sp[['Gender',\n",
    "                         'Fish',\n",
    "                         'Training',\n",
    "                         'Swimmer']],\n",
    "                     sp[['Gender',\n",
    "                         'Fish',\n",
    "                         'Training',\n",
    "                         'Control']]])\n",
    "sp2['Time'] = pandas.concat([sp2['Swimmer'].dropna(),\n",
    "                             sp2['Control'].dropna()])\n",
    "sp2['Experiment'] = ['Swimmer' if i > pandas.Timedelta(seconds=1) else 'Control' for i in sp2['Swimmer']]\n",
    "# Set that one fish back to NaN\n",
    "sp2.replace(9999, numpy.nan, inplace=True)\n",
    "# Set the massaged data back to the Morphology dataframe\n",
    "Speed = sp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfasdfasdf="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Now that we have all the data we need, we actually read the images in and do our processing to get to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Overviews (not into the dataframe, to keep things speedy)\n",
    "Overviews = [imageio.imread(o) for o in Data.OverviewName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display overviews (shadow projections)\n",
    "for c, o in enumerate(Overviews):\n",
    "    plt.subplot(lines, numpy.ceil(len(Data) / float(lines)), c + 1)\n",
    "    plt.imshow(o)\n",
    "    plt.gca().add_artist(ScaleBar(Data.PixelSize[c], 'um', color='black'))\n",
    "    plt.axis('off')\n",
    "    plt.title('%s' % Data.Sample[c])\n",
    "plt.suptitle('Overviews')\n",
    "plt.savefig(os.path.join(OutPutDir, 'Overviews.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert *all* VOI slices into single NumPy arrays and save them to disk\n",
    "# But only do this if we didn't do it already :)\n",
    "# Partially based on http://stackoverflow.com/a/39195332/323100\n",
    "# Since we reload/memorymap the stack below again, we overwrite the variable with NAN and clear the memory\n",
    "Data['OutputNameVOI'] = [os.path.join(f, sample + '_VOI.npy') for f, sample in zip(Data.Folder, Data.Sample)]\n",
    "# Don't save into the dataframe, or else we won't be able to make it :)\n",
    "VOIImages = [numpy.nan for file in Data.OutputNameVOI]\n",
    "for c, voi in enumerate(Data.OutputNameVOI):\n",
    "    # Only do this if we didn't do it already...\n",
    "    if os.path.exists(voi):\n",
    "        print('%2s/%s: %16s: Already saved to %s' % (c + 1, len(Data.Sample), Data.Sample[c], voi[len(RootFolder):]))\n",
    "    else:\n",
    "        print('%2s/%s: %16s: Reading %4s VOI images' % (c + 1, len(Data.Sample), Data.Sample[c], len(Data.VOINames[c])))\n",
    "        # Actually load the images now\n",
    "        VOIImages[c] = numpy.array([scipy.misc.imread(i, flatten=True) for i in Data.VOINames[c]])\n",
    "        # Save the images to NumPy binary files, disallowing pickle for portability\n",
    "        print('%23s: Saving to %s' % (Data.Sample[c], voi))\n",
    "        numpy.save(voi, VOIImages[c], allow_pickle=False)\n",
    "        # Clear memory\n",
    "        VOIImages[c] = numpy.nan\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free the memory of the images we loaded.\n",
    "# We 'memory-map' them again below\n",
    "%xdel VOIImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load (or memory-map) all the files.\n",
    "# This is loading the images like a virtual stack in ImageJ\n",
    "VOIImages = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameVOI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ourselves the middle slice to show\n",
    "Data['MiddleSliceName'] = [n[len(n) // 2] for n in Data.VOINames]\n",
    "Data['MiddleSlice'] = [i[len(i) // 2] for i in VOIImages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the middle slice of the VOI\n",
    "for c, m in enumerate(Data.MiddleSlice):\n",
    "    plt.subplot(lines, numpy.ceil(len(Data) / float(lines)), c + 1)\n",
    "    plt.imshow(m, vmax=0.618 * numpy.max(m))\n",
    "    plt.title('%s | VOI Slice %s' % (Data.Sample[c], os.path.basename(Data.MiddleSliceName[c])[-8:-4]))\n",
    "    plt.gca().add_artist(ScaleBar(Data.PixelSize[c], 'um'))\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Middle slices')\n",
    "plt.savefig(os.path.join(OutPutDir, 'MiddleSlices.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['NumberOfVOISlices'] = [len(v) for v in Data.VOINames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the VOI\n",
    "Data['VOIShape'] = [voi.shape for voi in VOIImages]\n",
    "Data['VOIVolume'] = [shape[0] * shape[1] * shape[2] for shape in Data.VOIShape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of VOI size and number of files is consistent.\n",
    "for i in range(20):\n",
    "    if len(Data.VOINames[i]) != len(VOIImages[i]):\n",
    "        print(Data.Sample[i])\n",
    "        print(len(Data.VOINames[i]))\n",
    "        print(Data.VOIShape[i][0])\n",
    "        print(len(VOIImages[i]))\n",
    "        print(80 * '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bragging reasons in the manuscript\n",
    "# All VOIs\n",
    "# Data[['Sample', 'VOIVolume', 'VOIShape']].sort_values('VOIVolume', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average volume\n",
    "print('The average volume is a cube of %s pixels' % int(round(Data.VOIVolume.mean() ** (1 / 3.))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The smallest VOIs\n",
    "Data[['Sample', 'VOIVolume', 'NumberOfVOISlices', 'VOIShape']].sort_values('VOIVolume', ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bragging reasons in the manuscript\n",
    "# The largest VOIs\n",
    "Data[['Sample', 'VOIVolume', 'NumberOfVOISlices', 'VOIShape']].sort_values('VOIVolume', ascending=True).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a manageable amount of equally spaced slices for thresholding and MIP-ing\n",
    "# NumberOfImagesToShow = 6\n",
    "# NumberOfImagesToShow = 16\n",
    "# NumberOfImagesToShow = 111\n",
    "# NumberOfImagesToShow = 222\n",
    "# NumberOfImagesToShow = 350\n",
    "# NumberOfImagesToShow = 1111\n",
    "NumberOfImagesToShow = Data.NumberOfVOISlices.max()  # just use all of them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the subset information\n",
    "Data['PrintEverySlice'] = [int(round(len(r) / NumberOfImagesToShow)) for r in Data.VOINames]\n",
    "Data['SubsetNames'] = [rn[::sw] for rn, sw in zip(Data.VOINames, Data.PrintEverySlice)]\n",
    "for c, i in enumerate(Data.Sample):\n",
    "    print('For %s we are working with a subset of %s (%0.1f %% of totally %s) equally '\n",
    "          'spaced slices' % (i,\n",
    "                             len(Data.SubsetNames[c]),\n",
    "                             len(Data.SubsetNames[c]) / len(Data.VOINames[c]) * 100,\n",
    "                             len(Data.VOINames[c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put len of 'UseThis' into dataframe\n",
    "Data['NumberOfAnalyzedVOISlices'] = [len((a)) for a in Data.SubsetNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the thresholds of each slice\n",
    "Data['OutputNameThreshold'] = [os.path.join(f,\n",
    "                                            sample + '_thresholds_from_%04d_of_%04d_slices.npy' % (len(n[::p]),\n",
    "                                                                                                   len(n)))\n",
    "                               for f, sample, n, p in zip(Data.Folder,\n",
    "                                                          Data.Sample,\n",
    "                                                          Data.VOINames,\n",
    "                                                          Data.PrintEverySlice)]\n",
    "Data['Threshold'] = [[numpy.nan] for s in Data.Sample]\n",
    "for c, thresholdname in enumerate(Data.OutputNameThreshold):\n",
    "    if os.path.exists(thresholdname):\n",
    "        print('%2s/%s: %16s: Grab values from %s' % (c + 1,\n",
    "                                                     len(Data),\n",
    "                                                     Data.Sample[c],\n",
    "                                                     thresholdname[len(RootFolder):]))\n",
    "        Data['Threshold'][c] = numpy.load(thresholdname)\n",
    "    else:\n",
    "        print('%2s/%s: %16s: Calculating thresholds for %s of %4s files' % (c + 1,\n",
    "                                                                            len(Data), Data.Sample[c],\n",
    "                                                                            len(Data.VOINames[c][::Data.PrintEverySlice[c]]),\n",
    "                                                                            len(Data.VOINames[c])))\n",
    "        Data['Threshold'][c] = [numpy.nan] * len(Data.VOINames[c][::Data.PrintEverySlice[c]])\n",
    "        for d, image in enumerate(VOIImages[c][::Data.PrintEverySlice[c]]):\n",
    "            try:\n",
    "                # Calculate and save threshold (of only the image, e.g. img[img>0])\n",
    "                Data['Threshold'][c][d] = skimage.filters.threshold_otsu(image[image > 0])\n",
    "            except (ValueError):\n",
    "                # Save NAN if we can't calculate a threshold\n",
    "                Data['Threshold'][c][d] = numpy.nan\n",
    "        print('%23s: Saving thresholds to %s' % (Data.Sample[c], thresholdname[len(RootFolder):]))\n",
    "        numpy.save(thresholdname, Data.Threshold[c], allow_pickle=False)\n",
    "        Data.Threshold[c] = numpy.nan\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load (or memory-map) all the files.\n",
    "# This is loading the images like a virtual stack in ImageJ\n",
    "Data['Threshold'] = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameThreshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the max, mean and median threshold for each sample\n",
    "Data['ThresholdMax'] = [numpy.nanmax(t) for t in Data.Threshold]\n",
    "# Discard the first and last $discard slices\n",
    "discard = 150\n",
    "Data['ThresholdAverage'] = [numpy.nanmean(t[discard:-discard]) for t in Data.Threshold]\n",
    "Data['ThresholdMedian'] = [numpy.nanmedian(t[discard:-discard]) for t in Data.Threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the Thresholds\n",
    "for c, i in enumerate(Data.Threshold):\n",
    "    plt.subplot(1, len(Data), c + 1)\n",
    "    seaborn.violinplot(i[discard:-discard], orient='v', color=Data.Color[c], cut=0)\n",
    "    plt.axhline(Data.ThresholdAverage[c], label='Average', color=Data.Color[c])\n",
    "    plt.axhline(Data.ThresholdMedian[c], label='Median', color=Data.Color[c], ls='dashed')\n",
    "    plt.ylim([0, Data.ThresholdMax.max() * 1.05])\n",
    "    if c:\n",
    "        plt.gca().axes.yaxis.set_ticklabels([])\n",
    "    else:\n",
    "        plt.ylabel('Threshold')\n",
    "    if '05' in Data.Sample[c]:\n",
    "        plt.legend()\n",
    "    plt.xlabel(Data.Sample[c], rotation=45)\n",
    "plt.suptitle('Otsu Thresholds for ~%s VOI slices' % NumberOfImagesToShow)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Thresholds_from%04dslices.png' % NumberOfImagesToShow))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the Thresholds\n",
    "for c, i in enumerate(Data.Threshold):\n",
    "    plt.subplot(lines, numpy.ceil(len(Data) / float(lines)), c + 1)\n",
    "    plt.plot(i[discard:-discard], color=Data.Color[c])\n",
    "    plt.plot(sorted(i[discard:-discard]), color=Data.Color[c], alpha=0.618)\n",
    "    plt.axhline(Data.ThresholdAverage[c], label='Average', color=Data.Color[c])\n",
    "    plt.axhline(Data.ThresholdMedian[c], label='Median', color=Data.Color[c], ls='dashed')\n",
    "    plt.ylim([0, Data.ThresholdMax.max() * 1.05])\n",
    "    plt.title(Data.Sample[c])\n",
    "    plt.gca().axes.xaxis.set_ticklabels([])\n",
    "    plt.gca().axes.yaxis.set_ticklabels([])\n",
    "    if '01' in Data.Sample[c]:\n",
    "        plt.legend()\n",
    "plt.suptitle('Otsu Thresholds for ~%s VOI slices' % NumberOfImagesToShow)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Thresholds-plot_from%04dslices.png' % NumberOfImagesToShow))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a subset of images\n",
    "Data['OutputNameVOISubset'] = [os.path.join(f,\n",
    "                                            sample + '_VOI_subset_from_%04d_of_%04d_slices.npy' % (len(n[::p]),\n",
    "                                                                                                   len(n)))\n",
    "                               for f, sample, n, p in zip(Data.Folder,\n",
    "                                                          Data.Sample,\n",
    "                                                          Data.VOINames,\n",
    "                                                          Data.PrintEverySlice)]\n",
    "# Don't save into the dataframe, or else we won't be able to make it to the end :)\n",
    "VOISubset = [numpy.nan for file in Data.OutputNameVOISubset]\n",
    "for c, subset in enumerate(Data.OutputNameVOISubset):\n",
    "    if len(Data.VOINames[c]) != len(Data.VOINames[c][::Data.PrintEverySlice[c]]):\n",
    "        # We are using a subset\n",
    "        # Only do this if we didn't do it already...\n",
    "        if os.path.exists(subset):\n",
    "            print('%2s/%s: %16s: Already saved to %s' % (c + 1,\n",
    "                                                         len(Data.Sample),\n",
    "                                                         Data.Sample[c],\n",
    "                                                         subset[len(RootFolder):]))\n",
    "        else:\n",
    "            print('%2s/%s: %16s: Subsetting %s of %s VOI images' % (c + 1,\n",
    "                                                                    len(Data.Sample),\n",
    "                                                                    Data.Sample[c],\n",
    "                                                                    len(Data.SubsetNames[c]),\n",
    "                                                                    len(Data.VOINames[c])))\n",
    "            VOISubset[c] = [numpy.nan] * len(Data.VOINames[c][::Data.PrintEverySlice[c]])\n",
    "            for d, image in enumerate(VOIImages[c][::Data.PrintEverySlice[c]]):\n",
    "                VOISubset[c][d] = image\n",
    "            print('%23s: Saving subset to %s' % (Data.Sample[c], subset[len(RootFolder):]))\n",
    "            numpy.save(subset, VOISubset[c], allow_pickle=False)\n",
    "            VOISubset[c] = numpy.nan\n",
    "            gc.collect()\n",
    "    else:\n",
    "        # We are using the full dataset\n",
    "        print('%2s/%s: %16s: Using the full dataset' % (c + 1, len(Data.Sample), Data.Sample[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the memory\n",
    "%xdel VOISubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load (or memory-map) all the files.\n",
    "if Data.PrintEverySlice[0] == 1:\n",
    "    # If we did NOT use a subset, load the original stack...\n",
    "    VOISubset = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameVOI]\n",
    "else:\n",
    "    # If we did use a subset, then load the subset\n",
    "    VOISubset = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameVOISubset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the longest samplename, https://stackoverflow.com/a/21295630/323100\n",
    "namelenmax = Data.Sample.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually threshold the images\n",
    "singlethreshold = True\n",
    "if singlethreshold:\n",
    "    Data['OutputNameThresholded'] = [os.path.join(f, 'VOI_thresholded-with-%0.2f.npy' % tm) for f, tm in zip(Data.Folder, Data.ThresholdAverage)]\n",
    "else:\n",
    "    Data['OutputNameThresholded'] = [os.path.join(f, 'VOI_thresholded-slicewise.npy') for f in Data.Folder]\n",
    "Thresholded = [numpy.nan for file in Data.OutputNameThreshold]\n",
    "for c, sample in Data.iterrows():\n",
    "    # Only do this if we didn't do it already...\n",
    "    if os.path.exists(sample.OutputNameThresholded):\n",
    "        print('%2s/%s: %s: Already saved to %s' % (c + 1,\n",
    "                                                   len(Data.Sample),\n",
    "                                                   sample.Sample.rjust(namelenmax),\n",
    "                                                   os.path.basename(sample.OutputNameThresholded)))\n",
    "    else:\n",
    "        print('%2s/%s: %s: Thresholding %3s VOI images' % (c + 1,\n",
    "                                                           len(Data.Sample),\n",
    "                                                           sample.Sample.rjust(namelenmax),\n",
    "                                                           len(sample.VOINames)))\n",
    "        Thresholded[c] = [None] * len(sample.VOINames)\n",
    "        for d, image in enumerate(VOISubset[c]):\n",
    "            if singlethreshold:\n",
    "                Thresholded[c][d] = image > sample.Threshold[d]\n",
    "            else:\n",
    "                Thresholded[c][d] = image > sample.ThresholdAverage\n",
    "        # Save the images to NumPy binary files, disallowing pickle for portability\n",
    "        print('%s: Saving to %s' % (os.path.basename(sample.Sample.rjust(namelenmax + 7)), sample.OutputNameThresholded))\n",
    "        numpy.save(sample.OutputNameThresholded, Thresholded[c], allow_pickle=False)\n",
    "        Thresholded[c] = numpy.nan\n",
    "        gc.collect()\n",
    "if singlethreshold:\n",
    "    print('\\n\\nWe were using a single threshold (ThresholdAverage) for *all* the images')\n",
    "else:\n",
    "    print('\\n\\nWe were using the Otsu threshold from each single image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thresholded = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameThresholded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display middle slices and thresholded equivalent\n",
    "# for c, fish in Data.iterrows():\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(VOIImages[c][len(VOIImages[c]) // 2])\n",
    "#     plt.title('%s: Middle slice (...%s)' % (fish.Sample, Data.VOINames[c][len(VOIImages[c]) // 2][-12:]))\n",
    "#     plt.gca().add_artist(ScaleBar(Data.PixelSize[c], 'um'))\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(Thresholded[c][len(Thresholded[c]) // 2])\n",
    "#     plt.title('Thresholded with %0.2f' % Data.ThresholdAverage[c])\n",
    "#     plt.gca().add_artist(ScaleBar(Data.PixelSize[c], 'um'))\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'MiddleSlices.%s.png' % fish.Sample))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save thresholded images out\n",
    "SaveImages = True\n",
    "if SaveImages:\n",
    "    # Save thresholded images\n",
    "    for c, folder in enumerate(Data.VOIFolder):\n",
    "        CurrentOutputFolder = os.path.join(folder, os.path.splitext(os.path.basename(Data.OutputNameThresholded[c]))[0])\n",
    "        if not os.path.exists(CurrentOutputFolder):\n",
    "            os.makedirs(CurrentOutputFolder)\n",
    "        if len(glob.glob(os.path.join(CurrentOutputFolder, '*.png'))) >= len(VOIImages[c]):\n",
    "            print('%2s/%s: %s: Already saved %s thresholded images to %s' % (c + 1,\n",
    "                                                                             len(Data),\n",
    "                                                                             Data.Sample[c].rjust(namelenmax),\n",
    "                                                                             len(VOIImages[c]),\n",
    "                                                                             CurrentOutputFolder[len(RootFolder) + 1:]))\n",
    "        else:\n",
    "            print('%2s/%s: %s: Saving %s thresholded images to %s' % (c + 1,\n",
    "                                                                      len(Data),\n",
    "                                                                      Data.Sample[c].rjust(namelenmax),\n",
    "                                                                      len(Thresholded[c]),\n",
    "                                                                      CurrentOutputFolder[len(RootFolder) + 1:]))\n",
    "            for d, i in enumerate(Thresholded[c]):\n",
    "                scipy.misc.imsave(os.path.join(CurrentOutputFolder,\n",
    "                                               Data.Sample[c] + '_thresholded_%04d.png' % d), i.astype('uint8') * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Display some original slices through the VOIs\n",
    "# SlicesToShow = 5\n",
    "# Iterator = [int(round(len(r) / SlicesToShow)) for r in Data.VOINames]\n",
    "# for c, sample in Data.iterrows():\n",
    "#     for i in range(SlicesToShow):\n",
    "#         plt.subplot(1,SlicesToShow,i+1)\n",
    "#         plt.imshow(VOIImages[c][::Iterator[c]][i])\n",
    "#         plt.axis('off')\n",
    "#         if i:\n",
    "#             plt.title('Slice %s' % i)\n",
    "#         else:\n",
    "#             plt.gca().add_artist(ScaleBar(sample.PixelSize, 'um', color='white'))\n",
    "#             plt.title(sample.Sample)\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'Sampler_%s_%s-images_originals.png' % (sample.Sample, SlicesToShow)))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Display some thresholded slices through the VOIs\n",
    "# for c, sample in Data.iterrows():\n",
    "#     for i in range(SlicesToShow):\n",
    "#         plt.subplot(1,SlicesToShow,i+1)\n",
    "#         plt.imshow(Thresholded[c][::Iterator[c]][i])\n",
    "#         plt.axis('off')\n",
    "#         if i:\n",
    "#             plt.title('Slice %s' % i)\n",
    "#         else:\n",
    "#             plt.gca().add_artist(ScaleBar(sample.PixelSize, 'um', color='white'))\n",
    "#             plt.title(sample.Sample)\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'Sampler_%s_%s-images_thresholded.png' % (sample.Sample, SlicesToShow)))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read or generate the MIPs\n",
    "Data['OutputNameMIP'] = [os.path.join(f,\n",
    "                                      sample + '_MIP_from_%04d_of_%04d_slices.npy' % (len(n[::p]),\n",
    "                                                                                      len(n)))\n",
    "                         for f, sample, n, p in zip(Data.Folder,\n",
    "                                                    Data.Sample,\n",
    "                                                    Data.VOINames,\n",
    "                                                    Data.PrintEverySlice)]\n",
    "MIPs = [None] * len(Data)\n",
    "for c, fn in enumerate(Data.OutputNameMIP):\n",
    "    if os.path.exists(fn):\n",
    "        print('%2s/%s: %16s: Loading %s into memory' % (c + 1,\n",
    "                                                        len(Data),\n",
    "                                                        Data.Sample[c],\n",
    "                                                        fn[len(RootFolder):]))\n",
    "        MIPs[c] = numpy.load(fn, mmap_mode='r')\n",
    "    else:\n",
    "        print('%2s/%s: %16s: Generating MIP from %s images' % (c + 1,\n",
    "                                                               len(Data),\n",
    "                                                               Data.Sample[c],\n",
    "                                                               len(Data.SubsetNames[c])))\n",
    "        MIPs[c] = numpy.max(VOISubset[c], axis=0)\n",
    "        numpy.save(fn, MIPs[c], allow_pickle=False)\n",
    "        # Free up memory\n",
    "        VOISubset[c]._mmap.close()\n",
    "        gc.collect()\n",
    "    # Save MIP to PNG image\n",
    "    scipy.misc.imsave(os.path.splitext(fn)[0] + '.png', MIPs[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display x,y,z-MIPs\n",
    "# for c, sample in enumerate(VOISubset):\n",
    "#     plt.imshow(numpy.max(sample, axis=1))\n",
    "#     plt.title(Data.Sample[c])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load (or memory-map) all the files again, since we closed them above.\n",
    "if Data.PrintEverySlice[0] == 1:\n",
    "    # If we did NOT use a subset, load the original stack...\n",
    "    VOISubset = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameVOI]\n",
    "else:\n",
    "    # If we did use a subset, then load the subset\n",
    "    VOISubset = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameVOISubset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 'through-the-sample' MIPs\n",
    "for c, m in enumerate(MIPs):\n",
    "    plt.subplot(lines, numpy.ceil(len(SampleNames) / float(lines)), c + 1)\n",
    "    plt.imshow(m)\n",
    "    plt.gca().add_artist(ScaleBar(Data.PixelSize[c], 'um'))\n",
    "    plt.title('%s (%s slices)' % (SampleNames[c], len(Data.SubsetNames[c])))\n",
    "    plt.axis('off')\n",
    "plt.suptitle('MIPs')\n",
    "plt.savefig(os.path.join(OutPutDir, 'MIPs_from%04dslices.png' % NumberOfImagesToShow))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the thresholds in the 60-80% range of the respective values\n",
    "split = 5\n",
    "Selected = [sorted(t)[(split - 2) * len(t) // split:(split - 1) * len(t) // split] for t in Data.Threshold]\n",
    "# mask the values of the threshold that are *not* in this range\n",
    "Otsu_selected = [numpy.ma.masked_outside(o, numpy.min(sel), numpy.max(sel)) for o, sel in zip(Data.Threshold, Selected)]\n",
    "# use the mean of this 60-80% value to threshold the datasets\n",
    "Data['Threshold6080'] = [numpy.nanmean(os) for os in Otsu_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the different thresholds\n",
    "# for c, s in enumerate(SampleNames):\n",
    "#     plt.plot(Data.Threshold[c], marker='', label='%s | Global Otsu Mean=%.2f | 60-80%% Otsu mean=%0.2f' % (s,\n",
    "#                                                                                                            Data.ThresholdAverage[c],\n",
    "#                                                                                                            Data.Threshold6080[c]),\n",
    "#              c=seaborn.color_palette(n_colors=len(SampleNames))[c])\n",
    "#     plt.plot(Otsu_selected[c], '.', ms=25, alpha=0.618, markeredgecolor='k', markeredgewidth=1,\n",
    "#              c=seaborn.color_palette(n_colors=len(Data))[c])\n",
    "#     plt.legend(loc='best')\n",
    "# plt.xlim([0, Data.NumberOfVOISlices.max()])\n",
    "# plt.title('Otsu thresholds for each slice of each sample')\n",
    "# plt.savefig(os.path.join(OutPutDir, 'Thresholds-all.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compare global Otsu threshold, 60%-80% selected threshold and threshold from MIPs\n",
    "# for c, s in enumerate(SampleNames):\n",
    "#     print('For %s we have a' % s)\n",
    "#     print('\\t- 60-80%% selected threshold of %0.2f' % Data.Threshold6080[c])\n",
    "#     print('\\t- global Otsu threshold of %0.2f' % Data.ThresholdAverage[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all (global) histograms\n",
    "if not True:\n",
    "    # This takes a while, since we 'ravel' all images from the subsets and calculate their histogram...\n",
    "    for c, s in enumerate(SampleNames):\n",
    "        plt.subplot(lines, numpy.ceil(len(SampleNames) / float(lines)), c + 1)\n",
    "        plt.hist(numpy.array(VOISubset[c]).ravel(),\n",
    "                 bins=32,\n",
    "                 log=True,\n",
    "                 color=Data.Color[c],\n",
    "                 label='%s | %s VOI slices' % (s, len(VOISubset[c])))\n",
    "        if CalculateAllThresholds:\n",
    "            plt.axvline(Data.Threshold6080[c],\n",
    "                        label='Selected Threshold: %0.2f' % Data.Threshold6080[c],\n",
    "                        c=seaborn.color_palette()[2])\n",
    "            plt.axvline(GlobalOtsu[c], label='Mean Otsu Threshold: %0.2f' % GlobalOtsu[c],\n",
    "                        c=seaborn.color_palette()[3])\n",
    "        plt.axvline(Otsu_MIP[c], label='MIP Otsu Threshold: %0.2f' % Otsu_MIP[c],\n",
    "                    c=seaborn.color_palette()[4])\n",
    "        plt.legend()\n",
    "        plt.xlim([0, 255])\n",
    "    plt.savefig(os.path.join(OutPutDir, 'Histograms_Thresholds_from%04dslices.png' % NumberOfImagesToShow))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the different thresholds\n",
    "plt.scatter(x=Data.Sample, y=Data.ThresholdAverage, label='Average Threshold', c=Data.Color, marker='x')\n",
    "plt.scatter(x=Data.Sample, y=Data.ThresholdMedian, label='Median Threshold', c=Data.Color, marker='d')\n",
    "plt.scatter(x=Data.Sample, y=Data.Threshold6080, label='60-80% lThreshold', c=Data.Color)\n",
    "plt.legend()\n",
    "plt.ylim([0, Data.ThresholdAverage.max() * 1.1])\n",
    "plt.xticks(rotation=90 * .618)\n",
    "plt.title('Thresholds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Show middle images with some data\n",
    "# plt.rcParams['figure.figsize'] = (16, 5)\n",
    "# for c, s in enumerate(SampleNames):\n",
    "#     maximum = skimage.filters.rank.maximum(Data.MiddleSlice[c].astype('uint8'), skimage.morphology.disk(25))\n",
    "#     plt.subplot(141)\n",
    "#     plt.imshow(Data.MiddleSlice[c])\n",
    "#     plt.gca().add_artist(ScaleBar(Data.PixelSize[c], 'um'))\n",
    "#     plt.title('Middle slice of %s' % s)\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(142)\n",
    "#     plt.imshow(Data.MiddleSlice[c], vmax=0.618 * numpy.max(Data.MiddleSlice[c]))\n",
    "#     plt.imshow(maximum, cmap='viridis', alpha=0.5)\n",
    "#     plt.gca().add_artist(ScaleBar(Data.PixelSize[c], 'um'))\n",
    "#     plt.title('%s\\nwith local maxima' % os.path.basename(Data.MiddleSliceName[c]))\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(143)\n",
    "#     plt.hist(Data.MiddleSlice[c].ravel(), bins=32, log=True, color=Data.Color[c])\n",
    "#     plt.axvline(Data.Threshold6080[c],\n",
    "#                 label='60-80%% Threshold: %0.2f' % Data.Threshold6080[c],\n",
    "#                 c=seaborn.color_palette()[2])\n",
    "#     plt.axvline(Data.ThresholdAverage[c], label='Threshold Average: %0.2f' % Data.ThresholdAverage[c],\n",
    "#                 c=seaborn.color_palette()[3])\n",
    "#     plt.legend(loc='best')\n",
    "#     plt.xlim([0, 255])\n",
    "#     plt.title('Histogram of middle slice')\n",
    "#     plt.subplot(144)\n",
    "#     plt.imshow(MIPs[c])\n",
    "#     plt.title('MIP of %s slices of %s' % (len(Data.SubsetNames[c]),\n",
    "#                                           Data.Sample[c]))\n",
    "#     plt.gca().add_artist(ScaleBar(Data.PixelSize[c], 'um'))\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'Details_%s.png' % Data.Sample[c]))\n",
    "#     plt.show()\n",
    "# plt.rcParams['figure.figsize'] = (16, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area_gills(image, threshold=None):\n",
    "    if not threshold:\n",
    "        # Calculate the Otsu threshold of the image if needed\n",
    "        try:\n",
    "            threshold = skimage.filters.threshold_otsu(image)\n",
    "        except (ValueError):\n",
    "            threshold = 0\n",
    "    thresholded_image = image > threshold\n",
    "    area_gills = numpy.sum(thresholded_image)\n",
    "    return(area_gills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the gill area (pythonic way, but without saving it in the middle...)\n",
    "# Data['AreaGills'] = [[calculate_area_gills(i, threshold=t)\n",
    "#                       for i, t in zip(subset, thrs)]\n",
    "#                      for subset, thrs in zip(VOISubset, Data.Threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gill area (slow way, but with saving it in the middle...)\n",
    "Data['OutputNameAreaGills'] = [os.path.join(f,\n",
    "                                            sample + '_area_gills_from_%04d_of_%04d_slices.npy' % (len(n[::p]),\n",
    "                                                                                                   len(n)))\n",
    "                               for f, sample, n, p in zip(Data.Folder,\n",
    "                                                          Data.Sample,\n",
    "                                                          Data.VOINames,\n",
    "                                                          Data.PrintEverySlice)]\n",
    "# Don't save into the dataframe, or else we won't be able to make it :)\n",
    "Data['AreaGills'] = [numpy.nan for file in Data.OutputNameAreaGills]\n",
    "for c, subset in enumerate(VOISubset):\n",
    "    # Only do this if we didn't do it already...\n",
    "    if os.path.exists(Data.OutputNameAreaGills[c]):\n",
    "        print('%2s/%s: %16s: Already saved to %s' % (c + 1,\n",
    "                                                     len(Data.Sample),\n",
    "                                                     Data.Sample[c],\n",
    "                                                     Data.OutputNameAreaGills[c][len(RootFolder):]))\n",
    "    else:\n",
    "        print('%2s/%s: %16s: Calculating gill area on %s of %s VOI images' % (c + 1,\n",
    "                                                                              len(Data.Sample),\n",
    "                                                                              Data.Sample[c],\n",
    "                                                                              len(Data.SubsetNames[c]),\n",
    "                                                                              len(Data.VOINames[c])))\n",
    "        Data.AreaGills[c] = [None] * len(subset)\n",
    "        for d, image in enumerate(subset):\n",
    "            Data.AreaGills[c][d] = calculate_area_gills(image, threshold=Data.Threshold[c][d])\n",
    "        print('%23s: Saving area to %s' % (Data.Sample[c], Data.OutputNameAreaGills[c][len(RootFolder):]))\n",
    "        numpy.save(Data.OutputNameAreaGills[c], Data.AreaGills[c], allow_pickle=False)\n",
    "        Data.AreaGills[c] = numpy.nan\n",
    "        # Free up memory\n",
    "        subset._mmap.close()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load (or memory-map) all the files again, since we closed them above.\n",
    "if Data.PrintEverySlice[0] == 1:\n",
    "    # If we did NOT use a subset, load the original stack...\n",
    "    VOISubset = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameVOI]\n",
    "else:\n",
    "    # If we did use a subset, then load the subset\n",
    "    VOISubset = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameVOISubset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save gills images out\n",
    "for c, sample in Data.iterrows():\n",
    "    sample['CurrentOutputFolder'] = os.path.join(os.path.dirname(sample.OutputNameVOI), 'VOI_thresholded_gills')\n",
    "    if not os.path.exists(sample.CurrentOutputFolder):\n",
    "        os.makedirs(sample.CurrentOutputFolder)\n",
    "    if len(glob.glob(os.path.join(sample.CurrentOutputFolder, '*.png'))) >= sample.NumberOfAnalyzedVOISlices:\n",
    "        print('%2s/%s: %7s: Already saved %3s thresholded images to %s' % (c + 1,\n",
    "                                                                           len(Data),\n",
    "                                                                           sample.Sample,\n",
    "                                                                           sample.NumberOfAnalyzedVOISlices,\n",
    "                                                                           sample.CurrentOutputFolder[len(RootFolder):]))\n",
    "    else:\n",
    "        print('%2s/%s: %7s: Saving %3s thresholded images to the disk' % (c + 1,\n",
    "                                                                          len(Data),\n",
    "                                                                          Data.Sample[c],\n",
    "                                                                          sample.NumberOfAnalyzedVOISlices))\n",
    "        for d, i in enumerate(VOISubset[c]):\n",
    "            t = i > Data.Threshold[c][d]\n",
    "            scipy.misc.imsave(os.path.join(sample.CurrentOutputFolder,\n",
    "                                           sample.Sample + '_thresholded_gills_%04d.png' % d), t.astype('uint8') * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area_organ(image, threshold=None, verbose=False):\n",
    "    if not threshold:\n",
    "        # Calculate the Otsu threshold of the image if needed\n",
    "        try:\n",
    "            threshold = skimage.filters.threshold_otsu(image)\n",
    "        except (ValueError):\n",
    "            threshold = 0\n",
    "    thresholded_image = image > threshold\n",
    "    binary_closing = True\n",
    "    if binary_closing:\n",
    "        # Use simple binary closing\n",
    "        closed = skimage.morphology.binary_closing(thresholded_image, selem=skimage.morphology.selem.disk(25))\n",
    "    else:\n",
    "        # Close small holes (this could be a bit more robust than simple binary closing)\n",
    "        imagearea = numpy.shape(image)[0] * numpy.shape(image)[1]\n",
    "        closed = skimage.morphology.remove_small_holes(thresholded_image, area_threshold=imagearea * 0.618)\n",
    "    if verbose:\n",
    "        # mask out Deas ROI\n",
    "        masked = numpy.ma.masked_equal(image, 0)\n",
    "        # Show the images\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(masked.filled(0))\n",
    "        plt.axis('off')\n",
    "        plt.title('Original')\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(thresholded_image)\n",
    "        plt.axis('off')\n",
    "        plt.title('Thresholded with %0.2f: %0.2g px' % (threshold, numpy.sum(thresholded_image)))\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(closed)\n",
    "        plt.axis('off')\n",
    "        plt.title('Closed: %0.2g px' % numpy.sum(closed))\n",
    "        plt.show()\n",
    "    area_organ = numpy.sum(closed)\n",
    "    return(area_organ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the (extrapolated) organ area (pythonic way, but without saving it in the middle...)\n",
    "# Data['AreaOrgan'] = [[calculate_area_organ(i, threshold=t)\n",
    "#                       for i, t in zip(subset, thrs)]\n",
    "#                      for subset, thrs in zip(VOISubset, Data.Threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the (extrapolated) organ area (slow way, but with saving it in the middle...)\n",
    "Data['OutputNameAreaOrgan'] = [os.path.join(f,\n",
    "                                            sample + '_area_organ_from_%04d_of_%04d_slices.npy' % (len(n[::p]),\n",
    "                                                                                                   len(n)))\n",
    "                               for f, sample, n, p in zip(Data.Folder,\n",
    "                                                          Data.Sample,\n",
    "                                                          Data.VOINames,\n",
    "                                                          Data.PrintEverySlice)]\n",
    "# Don't save into the dataframe, or else we won't be able to make it :)\n",
    "Data['AreaOrgan'] = [numpy.nan for file in Data.OutputNameAreaOrgan]\n",
    "for c, subset in enumerate(VOISubset):\n",
    "    # Only do this if we didn't do it already...\n",
    "    if os.path.exists(Data.OutputNameAreaOrgan[c]):\n",
    "        print('%2s/%s: %16s: Already saved to %s' % (c + 1,\n",
    "                                                     len(Data.Sample),\n",
    "                                                     Data.Sample[c],\n",
    "                                                     Data.OutputNameAreaOrgan[c][len(RootFolder):]))\n",
    "    else:\n",
    "        print('%2s/%s: %16s: Calculating organ area on %s of %s VOI images' % (c + 1,\n",
    "                                                                               len(Data.Sample),\n",
    "                                                                               Data.Sample[c],\n",
    "                                                                               len(Data.SubsetNames[c]),\n",
    "                                                                               len(Data.VOINames[c])))\n",
    "        Data.AreaOrgan[c] = [None] * len(subset)\n",
    "        for d, image in enumerate(subset):\n",
    "            print('Working on image %04s of %04s' % (d, len(Data.SubsetNames[c])), end=\"\\r\")\n",
    "            Data.AreaOrgan[c][d] = calculate_area_organ(image, threshold=Data.Threshold[c][d])\n",
    "        print('%23s: Saving area to %s' % (Data.Sample[c], Data.OutputNameAreaOrgan[c][len(RootFolder):]))\n",
    "        numpy.save(Data.OutputNameAreaOrgan[c], Data.AreaOrgan[c], allow_pickle=False)\n",
    "        Data.AreaOrgan[c] = numpy.nan\n",
    "        # Free up memory\n",
    "        subset._mmap.close()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load (or memory-map) all the files again, since we closed them above.\n",
    "if Data.PrintEverySlice[0] == 1:\n",
    "    # If we did NOT use a subset, load the original stack...\n",
    "    VOISubset = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameVOI]\n",
    "else:\n",
    "    # If we did use a subset, then load the subset\n",
    "    VOISubset = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameVOISubset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save organ area images out\n",
    "for c, sample in Data.iterrows():\n",
    "    sample['CurrentOutputFolder'] = os.path.join(os.path.dirname(sample.OutputNameVOI), 'VOI_organ_area')\n",
    "    if not os.path.exists(sample.CurrentOutputFolder):\n",
    "        os.makedirs(sample.CurrentOutputFolder)\n",
    "    if len(glob.glob(os.path.join(sample.CurrentOutputFolder, '*.png'))) >= sample.NumberOfAnalyzedVOISlices:\n",
    "        print('%2s/%s: %7s: Already saved %3s organ area images to %s' % (c + 1,\n",
    "                                                                          len(Data),\n",
    "                                                                          sample.Sample,\n",
    "                                                                          sample.NumberOfAnalyzedVOISlices,\n",
    "                                                                          sample.CurrentOutputFolder[len(RootFolder):]))\n",
    "    else:\n",
    "        print('%2s/%s: %7s: Saving %3s organ area images to the disk' % (c + 1,\n",
    "                                                                         len(Data),\n",
    "                                                                         Data.Sample[c],\n",
    "                                                                         sample.NumberOfAnalyzedVOISlices))\n",
    "        for d, i in enumerate(VOISubset[c]):\n",
    "            thresholded = i > Data.Threshold[c][d]\n",
    "            closed = skimage.morphology.binary_closing(thresholded, selem=skimage.morphology.selem.disk(25))\n",
    "            scipy.misc.imsave(os.path.join(sample.CurrentOutputFolder,\n",
    "                                           sample.Sample + '_area_organ_%04d.png' % d), closed.astype('uint8') * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['AreaGills'] = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameAreaGills]\n",
    "Data['AreaOrgan'] = [numpy.load(file, mmap_mode='r') for file in Data.OutputNameAreaOrgan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the images to get the volume of the gills and organ\n",
    "# This volume is obviously in voxels\n",
    "Data['VolumeGills'] = [numpy.sum(ag) for ag in Data.AreaGills]\n",
    "Data['VolumeOrgan'] = [numpy.sum(ao) for ao in Data.AreaOrgan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the volume in microliters\n",
    "Data['VolumeGills_ul'] = [vg * vv for vg, vv in zip(Data.VolumeGills, Data.VoxelVolume)]\n",
    "Data['VolumeOrgan_ul'] = [vo * vv for vo, vv in zip(Data.VolumeOrgan, Data.VoxelVolume)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ratio of gills per organ\n",
    "Data['GillsPerOrgan'] = [numpy.divide(ag, ao) for (ag, ao) in zip(Data['AreaGills'], Data['AreaOrgan'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots of the Areas\n",
    "for c, a in enumerate(Data.GillsPerOrgan):\n",
    "    plt.subplot(1, len(Data), c + 1)\n",
    "    seaborn.violinplot(a, orient='v', color=Data.Color[c], cut=0)\n",
    "#     seaborn.stripplot(a, orient='v', jitter=True, linewidth=1, s=5, color=Data.Color[c], alpha=0.318)\n",
    "    plt.ylim([0, 1.05])\n",
    "    if c:\n",
    "        plt.gca().axes.yaxis.set_ticklabels([])\n",
    "    else:\n",
    "        plt.ylabel('Gills per organ ratio')\n",
    "    plt.xlabel(Data.Sample[c], rotation=45)\n",
    "plt.suptitle('\"Gills per organ\" ratio for all images')\n",
    "plt.savefig(os.path.join(OutPutDir, 'Gills_per_organ_from%04dslices.png' % NumberOfImagesToShow))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean 'gills per organ' ratio\n",
    "Data['Mean_Gill_Ratio'] = [float(numpy.nanmean(a)) for a in Data['GillsPerOrgan']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data let's display all that we need!\n",
    "The plots below are the ones that are shown in the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change color palette from the default\n",
    "# seaborn.set_palette(seaborn.color_palette('viridis', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the fish length\n",
    "seaborn.violinplot(data=Morphology[['Length Control Before',\n",
    "                                    'Length Swimmer Before']],\n",
    "                   cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=Morphology[['Length Control Before',\n",
    "                                   'Length Swimmer Before']],\n",
    "                  s=10, linewidth=1.5, color='gray')\n",
    "plt.ylabel('Length (before training) [mm]')\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Lenghts-before.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the fish length\n",
    "seaborn.violinplot(data=Morphology[['Length Control After',\n",
    "                                    'Length Swimmer After']],\n",
    "                   cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=Morphology[['Length Control After',\n",
    "                                   'Length Swimmer After']],\n",
    "                  s=10, linewidth=1.5, color='gray')\n",
    "plt.ylabel('Length (after training) [mm]')\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Lenghts-after.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fish length\n",
    "seaborn.violinplot(data=Morphology[['Length Control Before',\n",
    "                                    'Length Control After',\n",
    "                                    'Length Swimmer Before',\n",
    "                                    'Length Swimmer After']],\n",
    "                   palette=(seaborn.color_palette()[0],\n",
    "                            seaborn.color_palette()[0],\n",
    "                            seaborn.color_palette()[1],\n",
    "                            seaborn.color_palette()[1]),\n",
    "                   cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=Morphology[['Length Control Before',\n",
    "                                   'Length Control After',\n",
    "                                   'Length Swimmer Before',\n",
    "                                   'Length Swimmer After']],\n",
    "                  s=10, linewidth=1.5, color='gray')\n",
    "plt.ylabel('Length [mm]')\n",
    "plt.gca().set_xticklabels(['Control\\nbefore',\n",
    "                           'Control\\nafter',\n",
    "                           'Swimmer\\nbefore',\n",
    "                           'Swimmer\\nafter'])\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Lenghts.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data as prose\n",
    "print('The length of the control group before training '\n",
    "      'was %0.2f mm with a STD of %0.2f.' % (Morphology['Length Control Before'].mean(),\n",
    "                                             Morphology['Length Control Before'].std()))\n",
    "print('The length of the control group after training '\n",
    "      'was %0.2f mm with a STD of %0.2f.' % (Morphology['Length Control After'].mean(),\n",
    "                                             Morphology['Length Control After'].std()))\n",
    "print('The length of the swimmer group before training '\n",
    "      'was %0.2f mm with a STD of %0.2f.' % (Morphology['Length Swimmer Before'].mean(),\n",
    "                                             Morphology['Length Swimmer Before'].std()))\n",
    "print('The length of the swimmer group after training '\n",
    "      'was %0.2f mm with a STD of %0.2f.' % (Morphology['Length Swimmer After'].mean(),\n",
    "                                             Morphology['Length Swimmer After'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The length of the controls increased by %0.2f %%' % percentage(Morphology['Length Control Before'].mean(),\n",
    "                                                                      Morphology['Length Control After'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The length of the swimmers increased by %0.2f %%' % percentage(Morphology['Length Swimmer Before'].mean(),\n",
    "                                                                      Morphology['Length Swimmer After'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fish weight\n",
    "# But only for the males, since the females carry eggs or not\n",
    "seaborn.violinplot(data=Morphology[Morphology.Gender == 'Male'][['Weight Control Before',\n",
    "                                                                 'Weight Swimmer Before']],\n",
    "                   cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=Morphology[Morphology.Gender == 'Male'][['Weight Control Before',\n",
    "                                                                'Weight Swimmer Before']],\n",
    "                  s=10, linewidth=1.5, color='gray')\n",
    "plt.ylabel('Weight [g]')\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Weights-before.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fish weight\n",
    "# But only for the males, since the females carry eggs or not\n",
    "seaborn.violinplot(data=Morphology[Morphology.Gender == 'Male'][['Weight Control After',\n",
    "                                                                 'Weight Swimmer After']],\n",
    "                   cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=Morphology[Morphology.Gender == 'Male'][['Weight Control After',\n",
    "                                                                'Weight Swimmer After']],\n",
    "                  s=10, linewidth=1.5, color='gray')\n",
    "plt.ylabel('Weight [g]')\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Weights-after.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fish weight\n",
    "# But only for the males, since the females carry eggs or not\n",
    "seaborn.violinplot(data=Morphology[Morphology.Gender == 'Male'][['Weight Control Before',\n",
    "                                                                 'Weight Control After',\n",
    "                                                                 'Weight Swimmer Before',\n",
    "                                                                 'Weight Swimmer After']],\n",
    "                   palette=(seaborn.color_palette()[0],\n",
    "                            seaborn.color_palette()[0],\n",
    "                            seaborn.color_palette()[1],\n",
    "                            seaborn.color_palette()[1]),\n",
    "                   cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=Morphology[Morphology.Gender == 'Male'][['Weight Control Before',\n",
    "                                                                'Weight Control After',\n",
    "                                                                'Weight Swimmer Before',\n",
    "                                                                'Weight Swimmer After']],\n",
    "                  s=10, linewidth=1.5, color='gray')\n",
    "plt.ylabel('Weight [g]')\n",
    "plt.gca().set_xticklabels(['Control\\nbefore',\n",
    "                           'Control\\nafter',\n",
    "                           'Swimmer\\nbefore',\n",
    "                           'Swimmer\\nafter'])\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Weights.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fish weight\n",
    "# But only for the males, since the females carry eggs or not\n",
    "seaborn.violinplot(data=Morphology[Morphology.Gender == 'Male'][['Weight Control Before',\n",
    "                                                                 'Weight Control After',\n",
    "                                                                 'Weight Swimmer Before',\n",
    "                                                                 'Weight Swimmer After']],\n",
    "                   palette=(seaborn.color_palette()[0],\n",
    "                            seaborn.color_palette()[0],\n",
    "                            seaborn.color_palette()[1],\n",
    "                            seaborn.color_palette()[1]),\n",
    "                   cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=Morphology[Morphology.Gender == 'Male'][['Weight Control Before',\n",
    "                                                                'Weight Control After',\n",
    "                                                                'Weight Swimmer Before',\n",
    "                                                                'Weight Swimmer After']],\n",
    "                  s=10, linewidth=1.5, color='gray')\n",
    "plt.ylabel('Weight [g]')\n",
    "plt.gca().set_xticklabels(['Control\\nbefore',\n",
    "                           'Control\\nafter',\n",
    "                           'Swimmer\\nbefore',\n",
    "                           'Swimmer\\nafter'])\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Weights.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data as prose\n",
    "print('The weight of the male control group before training  '\n",
    "      'was %0.3f g with a STD of %0.2f.' % (Morphology[Morphology.Gender == 'Male']['Weight Control Before'].mean(),\n",
    "                                            Morphology[Morphology.Gender == 'Male']['Weight Control Before'].std()))\n",
    "print('The weight of the male control group after training '\n",
    "      'was %0.3f g with a STD of %0.2f.' % (Morphology[Morphology.Gender == 'Male']['Weight Control After'].mean(),\n",
    "                                            Morphology[Morphology.Gender == 'Male']['Weight Control After'].std()))\n",
    "print('The weight of the male swimmer group before training'\n",
    "      ' was %0.3f g with a STD of %0.2f.' % (Morphology[Morphology.Gender == 'Male']['Weight Swimmer Before'].mean(),\n",
    "                                             Morphology[Morphology.Gender == 'Male']['Weight Swimmer Before'].std()))\n",
    "print('The weight of the male swimmer group after training '\n",
    "      'was %0.3f g with a STD of %0.2f.' % (Morphology[Morphology.Gender == 'Male']['Weight Swimmer After'].mean(),\n",
    "                                            Morphology[Morphology.Gender == 'Male']['Weight Swimmer After'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The weight of the controls increased by %0.2f %%' % percentage(Morphology[Morphology.Gender == 'Male']['Weight Control Before'].mean(),\n",
    "                                                                      Morphology[Morphology.Gender == 'Male']['Weight Control After'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The weight of the swimmers increased by %0.2f %%' % percentage(Morphology[Morphology.Gender == 'Male']['Weight Swimmer Before'].mean(),\n",
    "                                                                      Morphology[Morphology.Gender == 'Male']['Weight Swimmer After'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display filament count\n",
    "seaborn.violinplot(data=Filaments[['Control Count', 'Swimmer Count']],\n",
    "                   cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=Filaments[['Control Count', 'Swimmer Count']],\n",
    "                  s=10, linewidth=1.5, color='gray')\n",
    "plt.ylabel('Secondary filament count\\nof the five primary filaments')\n",
    "plt.gca().set_xticklabels(['Control', 'Swimmer'])\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Filament_count.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The mean secondary filament count for the control group was %0.2f with a STD of %0.2f.' % (Filaments['Control Count'].mean(),\n",
    "                                                                                                  Filaments['Control Count'].std()))\n",
    "print('The mean secondary filament count for the swimmers group was %0.2f with a STD of %0.2f.' % (Filaments['Swimmer Count'].mean(),\n",
    "                                                                                                   Filaments['Swimmer Count'].std()))\n",
    "print('This is an increase of %0.2f %%' % percentage(Filaments['Control Count'].mean(), Filaments['Swimmer Count'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display filament length\n",
    "seaborn.violinplot(data=Filaments[['Control Length', 'Swimmer Length']],\n",
    "                   cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=Filaments[['Control Length', 'Swimmer Length']],\n",
    "                  s=10, linewidth=1.5, color='gray')\n",
    "plt.ylabel(u'Primary filament length [\\u03bcm]')\n",
    "plt.gca().set_xticklabels(['Control', 'Swimmer'])\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Filament_lenght.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The mean filament length for the control was %0.f um with a STD of %0.f.' % (Filaments['Control Length'].mean(),\n",
    "                                                                                    Filaments['Control Length'].std()))\n",
    "print('The mean filament length for the swimmers was %0.f um with a STD of %0.f.' % (Filaments['Swimmer Length'].mean(),\n",
    "                                                                                     Filaments['Swimmer Length'].std()))\n",
    "print('This is an increase of %0.2f %%' % percentage(Filaments['Control Length'].mean(), Filaments['Swimmer Length'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the respirometry data\n",
    "# # Boxplot O2 normalized at start\n",
    "# seaborn.boxplot(data=Data, x='Experiment', y='O2 consumption start normalized')\n",
    "# seaborn.swarmplot(data=Data, x='Experiment', y='O2 consumption start normalized', s=10, linewidth=1.5)\n",
    "# label = False\n",
    "# if label:\n",
    "#     shift = 0.05\n",
    "#     for c, row in Data.iterrows():\n",
    "#         if Data.Experiment[c] == 'Control':\n",
    "#             plt.gca().annotate(Data.Sample[c], (0 + shift * numpy.random.rand(),\n",
    "#                                                 Data['O2 consumption start normalized'][c]),\n",
    "#                                horizontalalignment='left', verticalalignment='bottom')\n",
    "#         else:\n",
    "#             plt.gca().annotate(Data.Sample[c], (1 + shift * numpy.random.rand(),\n",
    "#                                                 Data['O2 consumption start normalized'][c]),\n",
    "#                                horizontalalignment='left', verticalalignment='bottom')\n",
    "# plt.ylabel('$O_{2}$ consumption normalized to fish length')\n",
    "# plt.title(('$O_{2}$ consumption at start of experiment'))\n",
    "# plt.ylim([0.015, 0.06])\n",
    "# if label:\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'O2_start_normalized.png'))\n",
    "# else:\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'O2_start_normalized_nolabel.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the respirometry data\n",
    "# # Boxplot O2 normalized at end\n",
    "# seaborn.boxplot(data=Data, x='Experiment', y='O2 consumption end normalized')\n",
    "# seaborn.swarmplot(data=Data, x='Experiment', y='O2 consumption end normalized', s=10, linewidth=1.5)\n",
    "# label = False\n",
    "# if label:\n",
    "#     shift = 0.05\n",
    "#     for c, row in Data.iterrows():\n",
    "#         if Data.Experiment[c] == 'Control':\n",
    "#             plt.gca().annotate(Data.Sample[c], (0 + shift * numpy.random.rand(),\n",
    "#                                                 Data['O2 consumption end normalized'][c]),\n",
    "#                                horizontalalignment='left', verticalalignment='bottom')\n",
    "#         else:\n",
    "#             plt.gca().annotate(Data.Sample[c], (1 + shift * numpy.random.rand(),\n",
    "#                                                 Data['O2 consumption end normalized'][c]),\n",
    "#                                horizontalalignment='left', verticalalignment='bottom')\n",
    "# plt.ylabel('$O_{2}$ consumption normalized to fish length')\n",
    "# plt.title(('$O_{2}$ consumption at end of experiment'))\n",
    "# plt.ylim([0.015, 0.06])\n",
    "# if label:\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'O2_end_normalized.png'))\n",
    "# else:\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'O2_end_normalized_nolabel.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display respirometry data\n",
    "seaborn.violinplot(data=respirometry, hue='Experiment', y='o2', x='Training', cut=0, inner='quartiles')\n",
    "seaborn.stripplot(data=respirometry, hue='Experiment', y='o2', x='Training',\n",
    "                  dodge=True, s=10, linewidth=1.5,\n",
    "                  palette=['gray', 'gray'])\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles[:len(handles) // 2], labels[:len(labels) // 2])\n",
    "plt.ylabel('$O_{2}$ consumption normalized to fish length')\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "plt.savefig(os.path.join(OutPutDir, 'O2_normalized.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The normalized O2 consumption for the control before '\n",
    "      'training was %0.4f with a STD of %0.4f.' % (Data[Data.Experiment == 'Control']['O2 consumption start normalized'].mean(),\n",
    "                                                   Data[Data.Experiment == 'Control']['O2 consumption start normalized'].std()))\n",
    "print('The normalized O2 consumption for the swimmers before '\n",
    "      'training was %0.4f with a STD of %0.4f.' % (Data[Data.Experiment == 'Swimmer']['O2 consumption start normalized'].mean(),\n",
    "                                                   Data[Data.Experiment == 'Swimmer']['O2 consumption start normalized'].std()))\n",
    "print('This is an increase of %0.2f %%' % percentage(Data[Data.Experiment == 'Control']['O2 consumption start normalized'].mean(),\n",
    "                                                     Data[Data.Experiment == 'Swimmer']['O2 consumption start normalized'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The normalized O2 consumption for the control after '\n",
    "      'training was %0.4f with a STD of %0.4f.' % (Data[Data.Experiment == 'Control']['O2 consumption end normalized'].mean(),\n",
    "                                                   Data[Data.Experiment == 'Control']['O2 consumption end normalized'].std()))\n",
    "print('The normalized O2 consumption for the swimmers after '\n",
    "      'training was %0.4f with a STD of %0.4f.' % (Data[Data.Experiment == 'Swimmer']['O2 consumption end normalized'].mean(),\n",
    "                                                   Data[Data.Experiment == 'Swimmer']['O2 consumption end normalized'].std()))\n",
    "print('This is an increase of %0.2f %%' % percentage(Data[Data.Experiment == 'Swimmer']['O2 consumption end normalized'].mean(),\n",
    "                                                     Data[Data.Experiment == 'Control']['O2 consumption end normalized'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Control start end: %0.2f %%' % percentage(Data[Data.Experiment == 'Control']['O2 consumption start normalized'].mean(),\n",
    "                                                 Data[Data.Experiment == 'Control']['O2 consumption end normalized'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Swimmer start end: %0.2f %%' % percentage(Data[Data.Experiment == 'Swimmer']['O2 consumption start normalized'].mean(),\n",
    "                                                 Data[Data.Experiment == 'Swimmer']['O2 consumption end normalized'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the area mean (after we did some statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro -> Normalitätstest\n",
    "scipy.stats.shapiro(Data.Mean_Gill_Ratio)\n",
    "# nicht signifikant von Normalverteilung unterschiedlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levene -> Varianztest\n",
    "scipy.stats.levene(Data.loc[Data.Experiment == 'Control'].Mean_Gill_Ratio,\n",
    "                   Data.loc[Data.Experiment == 'Swimmer'].Mean_Gill_Ratio)\n",
    "# nicht signifikant -> Wahrscheinlich nicht nicht normalverteilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Kolmogorov-Smirnov statistic on 2 samples -> Verteilungen nicht unterschiedlich?\n",
    "scipy.stats.ks_2samp(Data.loc[Data.Experiment == 'Control'].Mean_Gill_Ratio,\n",
    "                     Data.loc[Data.Experiment == 'Swimmer'].Mean_Gill_Ratio)\n",
    "# nicht signifikant -> wahrscheinlich nicht unterschiedliche Verteilung --> equal_var=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the means different?\n",
    "t_statistic, p_value = scipy.stats.ttest_ind(Data.loc[Data.Experiment == 'Control'].Mean_Gill_Ratio,\n",
    "                                             Data.loc[Data.Experiment == 'Swimmer'].Mean_Gill_Ratio,\n",
    "                                             equal_var=True)\n",
    "print(\"The difference between the 'Mean_Gill_Ratio' of 'Control' and 'Swimmer' has an\")\n",
    "# Two-sided test done, but we want one-sided test --> p_value / 2 (only because we tested it above)\n",
    "print('F value of %0.4s and a p value of %.2g.' % (t_statistic, p_value / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Boxplot of the mean area for each animal (calculated slice-wise)\n",
    "seaborn.violinplot(data=Data, x='Experiment', y='Mean_Gill_Ratio', cut=0)\n",
    "seaborn.swarmplot(data=Data, x='Experiment', y='Mean_Gill_Ratio', s=10, linewidth=1.5,\n",
    "                  color='k', alpha=0.309)\n",
    "label = False\n",
    "if label:\n",
    "    shift = 0.1\n",
    "    for c, row in Data.iterrows():\n",
    "        if Data.Experiment[c] == 'Control':\n",
    "            plt.gca().annotate(Data.Sample[c], (0 + shift * numpy.random.rand(),\n",
    "                                                Data.Mean_Gill_Ratio[c]),\n",
    "                               horizontalalignment='left', verticalalignment='bottom')\n",
    "        else:\n",
    "            plt.gca().annotate(Data.Sample[c], (1 + shift * numpy.random.rand(),\n",
    "                                                Data.Mean_Gill_Ratio[c]),\n",
    "                               horizontalalignment='left', verticalalignment='bottom')\n",
    "# plt.title('Average \"gills per organ\" from slices')\n",
    "plt.ylim(ymax=Data.Mean_Gill_Ratio.max() * 1.1)\n",
    "# statistical annotation, see vottom of https://github.com/jbmouret/matplotlib_for_papers\n",
    "plt.gca().annotate('',\n",
    "                   xy=(0, Data.Mean_Gill_Ratio.max()),\n",
    "                   xycoords='data',\n",
    "                   xytext=(1, Data.Mean_Gill_Ratio.max()),\n",
    "                   textcoords='data',\n",
    "                   arrowprops=dict(arrowstyle=\"-\", ec='#aaaaaa', connectionstyle=\"bar, fraction=0.1\"))\n",
    "plt.gca().text(0.5,\n",
    "               Data.Mean_Gill_Ratio.max() + abs(Data.Mean_Gill_Ratio.max() - Data.Mean_Gill_Ratio.min()) * 0.15,\n",
    "               significance(p_value / 2),\n",
    "               horizontalalignment='center',\n",
    "               verticalalignment='center')\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "if label:\n",
    "    plt.savefig(os.path.join(OutPutDir,\n",
    "                             'Gills_per_organ_average_slices_from%04dslices.png' % NumberOfImagesToShow))\n",
    "else:\n",
    "    plt.savefig(os.path.join(OutPutDir,\n",
    "                             'Gills_per_organ_average_slices_from%04dslices_nolabels.png' % NumberOfImagesToShow))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the volume data (after we did some statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro -> Normalitätstest\n",
    "scipy.stats.shapiro(Data.VolumeGills)\n",
    "# nicht signifikant von Normalverteilung unterschiedlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levene -> Varianztest\n",
    "scipy.stats.levene(Data.loc[Data.Experiment == 'Control'].VolumeGills,\n",
    "                   Data.loc[Data.Experiment == 'Swimmer'].VolumeGills)\n",
    "# nicht signifikant -> Wahrscheinlich nicht nicht normalverteilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Kolmogorov-Smirnov statistic on 2 samples -> Verteilungen nicht unterschiedlich?\n",
    "scipy.stats.ks_2samp(Data.loc[Data.Experiment == 'Control'].VolumeGills,\n",
    "                     Data.loc[Data.Experiment == 'Swimmer'].VolumeGills)\n",
    "# nicht signifikant -> wahrscheinlich nicht unterschiedliche Verteilung --> equal_var=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the means different?\n",
    "t_statistic, p_value = scipy.stats.ttest_ind(Data.loc[Data.Experiment == 'Control'].VolumeGills,\n",
    "                                             Data.loc[Data.Experiment == 'Swimmer'].VolumeGills,\n",
    "                                             equal_var=True)\n",
    "print(\"The difference between the 'gill volume' of 'Control' and 'Swimmer' has an\")\n",
    "# Two-sided test done, but we want one-sided test --> p_value / 2 (only because we tested it above)\n",
    "print('F value of %0.4s and a p value of %.2g.' % (t_statistic, p_value / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Boxplot of the gills volume for each animal (in voxels)\n",
    "# bars = seaborn.boxplot(data=Data, x='Experiment', y='VolumeGills')\n",
    "# seaborn.swarmplot(data=Data, x='Experiment', y='VolumeGills', s=10, linewidth=1)\n",
    "# label = False\n",
    "# if label:\n",
    "#     shift = 0.05\n",
    "#     for c, row in Data.iterrows():\n",
    "#         if Data.Experiment[c] == 'Control':\n",
    "#             plt.gca().annotate(Data.Sample[c], (0 + shift * numpy.random.rand(),\n",
    "#                                                 Data.VolumeGills[c]),\n",
    "#                                horizontalalignment='left', verticalalignment='bottom')\n",
    "#         else:\n",
    "#             plt.gca().annotate(Data.Sample[c], (1 + shift * numpy.random.rand(),\n",
    "#                                                 Data.VolumeGills[c]),\n",
    "#                                horizontalalignment='left', verticalalignment='bottom')\n",
    "# plt.ylabel('[voxels]')\n",
    "# plt.ylim(ymax=Data.VolumeGills.max() * 1.2)\n",
    "# # statistical annotation, see bottom of https://github.com/jbmouret/matplotlib_for_papers\n",
    "# plt.gca().annotate('',\n",
    "#                    xy=(0, Data.VolumeGills.max()),\n",
    "#                    xycoords='data',\n",
    "#                    xytext=(1, Data.VolumeGills.max()),\n",
    "#                    textcoords='data',\n",
    "#                    arrowprops=dict(arrowstyle=\"-\", ec='#aaaaaa', connectionstyle=\"bar, fraction=0.1\"))\n",
    "# plt.gca().text(0.5,\n",
    "#                Data.VolumeGills.max() + abs(Data.VolumeGills.max() - Data.VolumeGills.min()) * 0.15,\n",
    "#                significance(p_value / 2),\n",
    "#                horizontalalignment='center',\n",
    "#                verticalalignment='center')\n",
    "# plt.title('Gill volume')\n",
    "# if label:\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'Volume_Gills_from%04dslices.png' % NumberOfImagesToShow))\n",
    "# else:\n",
    "#     plt.savefig(os.path.join(OutPutDir, 'Volume_Gills_from%04dslices_nolabel.png' % NumberOfImagesToShow))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of the gills volume for each animal (in ul)\n",
    "bars = seaborn.violinplot(data=Data, x='Experiment', y='VolumeGills_ul', cut=0, inner='quartiles')\n",
    "seaborn.swarmplot(data=Data, x='Experiment', y='VolumeGills_ul', s=10, linewidth=1.5,\n",
    "                  color='gray')\n",
    "label = False\n",
    "if label:\n",
    "    shift = 0.05\n",
    "    for c, row in Data.iterrows():\n",
    "        if Data.Experiment[c] == 'Control':\n",
    "            plt.gca().annotate(Data.Sample[c], (0 + shift * numpy.random.rand(),\n",
    "                                                Data.VolumeGills_ul[c]),\n",
    "                               horizontalalignment='left', verticalalignment='bottom')\n",
    "        else:\n",
    "            plt.gca().annotate(Data.Sample[c], (1 + shift * numpy.random.rand(),\n",
    "                                                Data.VolumeGills_ul[c]),\n",
    "                               horizontalalignment='left', verticalalignment='bottom')\n",
    "plt.ylabel(u'[\\u03bcl]')  # https://stackoverflow.com/a/2140991/323100\n",
    "plt.ylim(ymax=Data.VolumeGills_ul.max() * 1.2)\n",
    "# statistical annotation, see bottom of https://github.com/jbmouret/matplotlib_for_papers\n",
    "plt.gca().annotate('',\n",
    "                   xy=(0, Data.VolumeGills_ul.max()),\n",
    "                   xycoords='data',\n",
    "                   xytext=(1, Data.VolumeGills_ul.max()),\n",
    "                   textcoords='data',\n",
    "                   arrowprops=dict(arrowstyle=\"-\", ec='#aaaaaa', connectionstyle=\"bar, fraction=0.1\"))\n",
    "plt.gca().text(0.5,\n",
    "               Data.VolumeGills_ul.max() + abs(Data.VolumeGills_ul.max() - Data.VolumeGills_ul.min()) * 0.15,\n",
    "               significance(p_value / 2),\n",
    "               horizontalalignment='center',\n",
    "               verticalalignment='center')\n",
    "plt.title('Gill volume')\n",
    "seaborn.despine(offset=10, trim=True, bottom=True)\n",
    "if label:\n",
    "    plt.savefig(os.path.join(OutPutDir, 'Volume_Gills_ul_from%04dslices.png' % NumberOfImagesToShow))\n",
    "else:\n",
    "    plt.savefig(os.path.join(OutPutDir, 'Volume_Gills_ul_from%04dslices_nolabel.png' % NumberOfImagesToShow))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean volume of the gills\n",
    "print('The \"control\" fishes have a mean gill volume of %0.3f ul'\n",
    "      % Data[Data.Experiment == 'Control'].VolumeGills_ul.mean())\n",
    "print('The \"swimmer\" fishes have a mean gill volume of %0.3f ul'\n",
    "      % Data[Data.Experiment == 'Swimmer'].VolumeGills_ul.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the volume normalized to the fish length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['VolumeGillsNormalized'] = [numpy.divide(gv, w) for gv, w in zip(Data.VolumeGills_ul, Data.Length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro -> Normalitätstest\n",
    "scipy.stats.shapiro(Data.VolumeGillsNormalized)\n",
    "# nicht signifikant von Normalverteilung unterschiedlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levene -> Varianztest\n",
    "scipy.stats.levene(Data.loc[Data.Experiment == 'Control'].VolumeGillsNormalized,\n",
    "                   Data.loc[Data.Experiment == 'Swimmer'].VolumeGillsNormalized)\n",
    "# nicht signifikant -> Wahrscheinlich nicht nicht normalverteilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Kolmogorov-Smirnov statistic on 2 samples -> Verteilungen nicht unterschiedlich?\n",
    "scipy.stats.ks_2samp(Data.loc[Data.Experiment == 'Control'].VolumeGillsNormalized,\n",
    "                     Data.loc[Data.Experiment == 'Swimmer'].VolumeGillsNormalized)\n",
    "# knapp nicht signifikant -> wahrscheinlich nicht unterschiedliche Verteilung --> equal_var=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the means different?\n",
    "t_statistic, p_value = scipy.stats.ttest_ind(Data.loc[Data.Experiment == 'Control'].VolumeGillsNormalized,\n",
    "                                             Data.loc[Data.Experiment == 'Swimmer'].VolumeGillsNormalized,\n",
    "                                             equal_var=True)\n",
    "print(\"The difference between the 'normalized gill volume' of 'Control' and 'Swimmer' has an\")\n",
    "# Two-sided test done, but we want one-sided test --> p_value / 2 (only because we tested it above)\n",
    "print('F value of %0.4s and a p value of %.2g.' % (t_statistic, p_value / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of the NORMALIZED gill volumes\n",
    "seaborn.violinplot(data=Data, x='Experiment', y='VolumeGillsNormalized', cut=0)\n",
    "seaborn.swarmplot(data=Data, x='Experiment', y='VolumeGillsNormalized', s=10, linewidth=1.5,\n",
    "                  color='k', alpha=0.309)\n",
    "label = False\n",
    "if label:\n",
    "    shift = 0.05\n",
    "    for c, row in Data.iterrows():\n",
    "        if Data.Experiment[c] == 'Control':\n",
    "            plt.gca().annotate(Data.Sample[c], (0 + shift * numpy.random.rand(),\n",
    "                                                Data.VolumeGillsNormalized[c]),\n",
    "                               horizontalalignment='left', verticalalignment='bottom')\n",
    "        else:\n",
    "            plt.gca().annotate(Data.Sample[c], (1 + shift * numpy.random.rand(),\n",
    "                                                Data.VolumeGillsNormalized[c]),\n",
    "                               horizontalalignment='left', verticalalignment='bottom')\n",
    "# plt.title('Normalized gill volume (normalized to fish length)')\n",
    "plt.ylim(ymax=Data.VolumeGillsNormalized.max() * 1.2)\n",
    "# statistical annotation, see bottom of https://github.com/jbmouret/matplotlib_for_papers\n",
    "plt.gca().annotate('',\n",
    "                   xy=(0, Data.VolumeGillsNormalized.max()),\n",
    "                   xycoords='data',\n",
    "                   xytext=(1, Data.VolumeGillsNormalized.max()),\n",
    "                   textcoords='data',\n",
    "                   arrowprops=dict(arrowstyle=\"-\", ec='#aaaaaa', connectionstyle=\"bar, fraction=0.1\"))\n",
    "plt.gca().text(0.5,\n",
    "               Data.VolumeGillsNormalized.max() + abs(Data.VolumeGillsNormalized.max() - Data.VolumeGillsNormalized.min()) * 0.15,\n",
    "               significance(p_value / 2),\n",
    "               horizontalalignment='center',\n",
    "               verticalalignment='center')\n",
    "plt.ylabel('ul/mm')\n",
    "if label:\n",
    "    plt.savefig(os.path.join(OutPutDir, 'Volume_Gills_Normalized_ul_from%04dslices.png' % NumberOfImagesToShow))\n",
    "else:\n",
    "    plt.savefig(os.path.join(OutPutDir, 'Volume_Gills_Normalized_ul_from%04slies_nolabels.png' % NumberOfImagesToShow))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data at the end\n",
    "Data.to_csv('Data_%s.csv' % get_git_hash())\n",
    "Data.to_csv(os.path.join(OutPutDir, 'Data_%s.csv' % get_git_hash()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All data has been saved to %s' % os.path.join(OutPutDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
